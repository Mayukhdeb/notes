<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>THINGS: a multimodal dataset for investigating object representations in thehuman brain</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../style.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">THINGS: a multimodal dataset for investigating object representations in thehuman brain</h1>
</header>
<p>+++ title = “THINGS: a multimodal dataset for investigating object representations in thehuman brain” date = “2023-04-04” author = “Mayukh Deb” tags = [“paper”] +++</p>
<p>It’s actually a collection of 3 datasets. All of which can be found <a href="https://openneuro.org/datasets/ds004212/versions/2.0.0">here</a>. The images used can be found <a href="https://things-initiative.org/">here</a>.</p>
<p>The 3 datasets are: 1. FMRI scans from 3 participants. 8740 images. 2. MEG scans. 4 participants. 22k images. 3. 12k participants. 4.7 million similarity judgements.</p>
<p>The 2 main datasets I’m interested in are the MEG scans and the similarity judgements. For the MEG scans, we can use <a href="https://github.com/ViCCo-Group/THINGS-data/tree/main/MEG">these scripts</a> as boilerplate.</p>
<p>For now lets stick to MEG as planned.</p>
<p>Notes on MEG data collection: - Each session consisted of 10 runs (~5 min each). - In each run, 185–186 object images were presented, as well as 20 test and 20 catch images - Stimuli were presented for 500ms - 225–226 trials per run, 2,254 trials per session - 27,048 trials per participant - Stimulus presentation was done with Psychtoolbox</p>
<p>Metadata for a single MEG run for session 1 run 9:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a>{</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>    <span class="st">&quot;TaskName&quot;</span>: <span class="st">&quot;main&quot;</span>,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    <span class="st">&quot;Manufacturer&quot;</span>: <span class="st">&quot;CTF&quot;</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    <span class="st">&quot;PowerLineFrequency&quot;</span>: <span class="dv">60</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>    <span class="st">&quot;SamplingFrequency&quot;</span>: <span class="fl">1200.0</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>    <span class="st">&quot;SoftwareFilters&quot;</span>: <span class="st">&quot;n/a&quot;</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>    <span class="st">&quot;RecordingDuration&quot;</span>: <span class="fl">347.99916666666667</span>,</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>    <span class="st">&quot;RecordingType&quot;</span>: <span class="st">&quot;continuous&quot;</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>    <span class="st">&quot;DewarPosition&quot;</span>: <span class="st">&quot;n/a&quot;</span>,</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>    <span class="st">&quot;DigitizedLandmarks&quot;</span>: false,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a>    <span class="st">&quot;DigitizedHeadPoints&quot;</span>: false,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>    <span class="st">&quot;MEGChannelCount&quot;</span>: <span class="dv">272</span>,</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>    <span class="st">&quot;MEGREFChannelCount&quot;</span>: <span class="dv">28</span>,</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true"></a>    <span class="st">&quot;EEGChannelCount&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true"></a>    <span class="st">&quot;EOGChannelCount&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true"></a>    <span class="st">&quot;ECGChannelCount&quot;</span>:<span class="op">+</span> <span class="dv">0</span>,</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true"></a>    <span class="st">&quot;EMGChannelCount&quot;</span>: <span class="dv">0</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true"></a>    <span class="st">&quot;MiscChannelCount&quot;</span>: <span class="dv">10</span>,</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true"></a>    <span class="st">&quot;TriggerChannelCount&quot;</span>: <span class="dv">0</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true"></a>}</span></code></pre></div>
<p>I think <code>"MEGChannelCount": 272</code> refers to the fact that we have 272 channels. So if we average along the time dimension, then for each instance, we get a tensor of shape <code>272</code>.</p>
<p>Files like <a href="https://openneuro.org/datasets/ds004212/versions/2.0.0/file-display/sub-BIGMEG1:ses-11:meg:sub-BIGMEG1_ses-11_task-main_run-01_events.tsv">these</a> contain the index of the image used (most probably it’s that)</p>
<p><strong>Open questions:</strong> 1. what is <code>TRIAL_TYPE</code>? (values: <code>['exp', 'test', 'catch'...]</code>)</p>
</body>
</html>
