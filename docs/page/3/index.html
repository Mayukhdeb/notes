<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>


  





<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="page-heading">
        
          <h1>Notes</h1>
          
            <p class="author">Mayukh Deb</p>

            
              <div class="abstract">
                <h5>Abstract</h5>
                <p>
                  This is a place to keep my notes, mostly from the papers I read and find interesting.
                </p>
              </div>
            
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2023-01-01-neural-taskonomy/">
      <h2 class="post-title">Neural Taskonomy - using encodings from vision models to understand the human brain</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Jan 1, 2023
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Intro CNNs are not too bad at predicting brain activity. But using their intermediate encoding space seems to be not too effective as a way to understand the how the human brain works.
So instead of using a single CNN as a source of visual features, the authors thought that it&rsquo;s a good idea to build encoding models from multiple models which were trained for different vision tasks (segmentation, classification, etc).</p>
        <a href="https://mayukhdeb.github.io/notes/post/2023-01-01-neural-taskonomy/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-12-25-diffusion/">
      <h2 class="post-title">Order From Chaos (Part 1): Diffusion for image synthesis explained in simple words</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Dec 25, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Warning: This post is still being written and is not complete, I just uploaded a draft.
Intro If you take and image and iteratively add very small amounts of noise to it, eventually the image would be unrecongnizable to the eye &ndash; Now what if we could undo this process?
Start from noise, and then iteratively remove the noise until you end up with the real image again.
The Forward and backward processes Given an image \(X_0\), we would want to convert it to \(X_T\) by gradually adding noise to \(X_0\) in \(T\) time steps.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-12-25-diffusion/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-12-25-diffusion-code/">
      <h2 class="post-title">Order From Chaos (Part 2): Diffusion for image synthesis explained in code and a little bit of math</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Dec 25, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Warning: This post is still being written and is not complete, I just uploaded a draft.
This post is basically what I learned while watching this video by DeepFindr.
Diffusion models work by destroying an input gradually until it looks like noise and then recovering the input image from that. The forward process is hardcoded, and the reverse process is trainable.
In the reverse process, the task of the model is to predict the noise that was added in each step to the input image.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-12-25-diffusion-code/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
    <ul class="pager">
      
        <li class="previous">
          <a href="https://mayukhdeb.github.io/notes/page/2/">&larr; Newer</a>
        </li>
      
      
        <li class="next">
          <a href="https://mayukhdeb.github.io/notes/page/4/">Older &rarr;</a>
        </li>
      
    </ul>
  
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2023
      </p>
  </div>
</footer></body>
</html>
