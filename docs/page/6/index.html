<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>


  





<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="page-heading">
        
          <h1>Notes</h1>
          
            <p class="author">Mayukh Deb</p>

            
              <div class="abstract">
                <h5>Abstract</h5>
                <p>
                  This is a place to keep my notes, mostly from the papers I read and find interesting.
                </p>
              </div>
            
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-08-07-parti-image-generation/">
      <h2 class="post-title">Parti - Scaling LLMs for Text to Image tasks</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Aug 7, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Scaling Autoregressive Models for Content-Rich Text to Image Generation The architecture itself that&rsquo;s used for parti (that&rsquo;s what the authors call this model) is fairly simple. It&rsquo;s a transformer encoder-decoder architecture paired with a ViT VQGAN in the end to tokenize/detokenize images.
How do we tokenize images? For an autoregressive model to work, we basically have to convert everything to tokens. Tokenizing text is super easy. The problem in this case is that we also have to convert images into a sequence of tokens.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-08-07-parti-image-generation/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-08-01-the-third-wave/">
      <h2 class="post-title">The Third Wave (?)</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Aug 1, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>I will start by rambling a little about how learning language is harder than you think. Then I&rsquo;ll move on to the main paper itself.
Learning language is harder than you think An interesting point that was made in the article was that a language is learned not entirely through memorization. Sentences like I breaked the window are grammatically invalid, but they still manage to get the meaning accross. We manage to make a meaningful fact tuple i.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-08-01-the-third-wave/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-19-07-locating-and-editing-factual-associations-in-gpt/">
      <h2 class="post-title">Locating and Editing Factual Knowledge in GPTs</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Jul 19, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>This paper&rsquo;s approach has been to develop a mechanism to identify the neuron activations that lead to a model&rsquo;s factual predictions and possibly even edit existing facts.
Key concepts and takeaways: What is a fact tuple? It is a special way to store knowledge in the form of a tuple which looks like the following:
## (subject, relation, object) (&#34;Edmunt Neupert&#34;, &#34;Plays the instrument&#34;, &#34;Piano&#34;) It contains the subject (index 0), the object (index 2) and their relation (index 1).</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-19-07-locating-and-editing-factual-associations-in-gpt/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
    <ul class="pager">
      
        <li class="previous">
          <a href="https://mayukhdeb.github.io/notes/page/5/">&larr; Newer</a>
        </li>
      
      
        <li class="next">
          <a href="https://mayukhdeb.github.io/notes/page/7/">Older &rarr;</a>
        </li>
      
    </ul>
  
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2023
      </p>
  </div>
</footer></body>
</html>
