<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Neural Taskonomy - using encodings from vision models to understand the human brain - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>Neural Taskonomy - using encodings from vision models to understand the human brain</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
  <div class="container" role="main">
    <article class="article" class="blog-post">
      <div class="postmeta">
        <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Jan 1, 2023
  
</span>
      </div>
      <br>
      
    <h2 id="intro">Intro</h2>
<p>CNNs are not too bad at predicting brain activity. But using their intermediate encoding space seems to be not too effective as a way to understand the how the human brain works.</p>
<p>So instead of using a single CNN as a source of visual features, the authors thought that it&rsquo;s a good idea to build encoding models from multiple models which were trained for different vision tasks (segmentation, classification, etc).</p>
<p>They extracted the features describing each of the stimulus images and used them to train a model to predict brain responses. Their reasoning being:</p>
<p>Given a model <code>M</code> that was trained for a task <code>T</code> (where <code>T</code> could be: segmentation, depth estimation, object detection, etc). We can infer that if an encoding from a model <code>M</code> is a good predictor of a specific brain region, information about that task <code>T</code> is likely encoded in that region.</p>
<h2 id="method">Method</h2>
<p>The authors fed the image into the network and extracted an intermediate layer activation from the models. These values are used as regressors in a ridge regression model to predict brain responses to that image.</p>
<p>The outputs of these models are then analysed and they are basically then able to make a &ldquo;matrix&rdquo; of tasks, where they show that the brain-signal predictions of certain tasks are correlated, while others are not.</p>
<!-- ## Personal notes

- Can we use a combination of these encoders to build a model which can be finetuned to make embeddings for an LLM? --><blockquote>
</blockquote>



      
        <div class="blog-tags">
          
            <a href="https://mayukhdeb.github.io/notes//tags/paper/">paper</a>&nbsp;
          
        </div>
      
    </article>
    
  </div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about"></a>
        &copy;
        2023
      </p>
  </div>
</footer></body>
</html>
