<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Locating and Editing Factual Knowledge in GPTs - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>Locating and Editing Factual Knowledge in GPTs</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
  <div class="container" role="main">
    <article class="article" class="blog-post">
      <div class="postmeta">
        <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Jul 19, 2022
  
</span>
      </div>
      <br>
      
    <p>This paper&rsquo;s approach has been to develop a mechanism to identify the neuron activations that lead to a model&rsquo;s factual predictions and possibly even edit existing facts.</p>
<h2 id="key-concepts-and-takeaways">Key concepts and takeaways:</h2>
<h3 id="what-is-a-fact-tuple"><strong>What is a fact tuple?</strong></h3>
<p>It is a special way to store knowledge in the form of  a tuple which looks like the following:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">## (subject, relation, object)</span>
(<span style="color:#e6db74">&#34;Edmunt Neupert&#34;</span>, <span style="color:#e6db74">&#34;Plays the instrument&#34;</span>, <span style="color:#e6db74">&#34;Piano&#34;</span>)
</code></pre></div><p>It contains the subject (index 0), the object (index 2) and their relation (index 1).</p>
<h3 id="knowing-differs-from-saying"><strong>Knowing differs from saying</strong></h3>
<p>Just because an LLM &ldquo;knows&rdquo; a fact, does not always mean that it&rsquo;ll state it in the completion. This is because transformers are pretty sensitive to the prompt itself.</p>
<p>Just how LLMs can <strong>say</strong> something without actually <strong>knowing</strong> it, it can also <strong>know</strong> something without <strong>saying</strong> it.</p>
<h3 id="what-is-knowledge-in-a-llm-if-it-exists-is-there-an-elementary-unit-of-knowledge-within-the-models"><strong>What is knowledge in a LLM? If it exists, is there an elementary unit of knowledge within the models?</strong></h3>
<p><strong>What if there was some specific computation within the LLM which plays a devcisive role for a given fact?</strong></p>
<p>It is fair to assume that a certain fact stored within the model is  evenly distributed among all of the computations being performed during the forward pass, but that is generally not the case. It turns out that when we corrupt the embeddings of certain input tokens, the probability of the original output changes drastically.</p>
<p>The question is, which part of the model and the prompt was responsible for this decisive change?</p>
<p>Let&rsquo;s try to understand this with an example:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
</code></pre></div><p>(WIP)</p>



      
        <div class="blog-tags">
          
            <a href="https://mayukhdeb.github.io/notes//tags/paper/">paper</a>&nbsp;
          
        </div>
      
    </article>
    
  </div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2022
      </p>
  </div>
</footer></body>
</html>
