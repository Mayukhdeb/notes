<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Writing - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>Writing</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2023-05-10-brain-inspired-model-training/">
      <h2 class="post-title">BIMT: Brain Inspired Modular Training</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>May 10, 2023
  
</span>
  </div>
  <div class="post-entry">
    
      <p>When compared to artificial neural networks, the human brain is a lot more modular. The authors believe that this is because the loss function of ANN regularizers like weight decay are not dependent on the permutations of neurons on each layer.
The cost of connecting 2 biological neurons which are far apart is much more than when they&rsquo;re closer together. But this is not the case for ANNs.
In order to impose a similar phenomenon to that of brains, the authors propose the following steps:</p>
        <a href="https://mayukhdeb.github.io/notes/post/2023-05-10-brain-inspired-model-training/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2023-04-20-audioclip/">
      <h2 class="post-title">AudioCLIP: Extending CLIP to Image, Text and Audio</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 20, 2023
  
</span>
  </div>
  <div class="post-entry">
    
      <p>They aim to train a tri-modal model which provides a common embedding space for 3 modalities: Images, text and Audio. The trick lies in adding in the 3rd modality (audio)
The repo can be found here.
There are 3 components to this model:
 Image encoder Text encoder Audio Encoder (ESResNeXt)  The image and the text encoder were taken from the original pre-trained CLIP model. The Audio encoder was then first pre-trained on the AudioSet dataset until it achieved a reasonably high accuracy.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2023-04-20-audioclip/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2023-04-04-things-meg-dataset/">
      <h2 class="post-title">THINGS: a multimodal dataset for investigating object representations in thehuman brain</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 4, 2023
  
</span>
  </div>
  <div class="post-entry">
    
      <p>It&rsquo;s actually a collection of 3 datasets. All of which can be found here. The images used can be found here.
The 3 datasets are:
 FMRI scans from 3 participants. 8740 images. MEG scans. 4 participants. 22k images. 12k participants. 4.7 million similarity judgements.  The 2 main datasets I&rsquo;m interested in are the MEG scans and the similarity judgements. For the MEG scans, we can use these scripts as boilerplate.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2023-04-04-things-meg-dataset/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
    <ul class="pager">
      
      
        <li class="next">
          <a href="https://mayukhdeb.github.io/notes/post/page/2/">Older &rarr;</a>
        </li>
      
    </ul>
  
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2023
      </p>
  </div>
</footer></body>
</html>
