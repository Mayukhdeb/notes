<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Open Vocabulary EEG-To-Text Decoding - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>Open Vocabulary EEG-To-Text Decoding</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
  <div class="container" role="main">
    <article class="article" class="blog-post">
      <div class="postmeta">
        <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Mar 9, 2023
  
</span>
      </div>
      <br>
      
    <p>The primary problem with most of the existing Brain-Signal to text pipelines is that they have a closed vocabulary.</p>
<p>In this paper, they use pretrained language models for
EEG-To-Text decoding and make a zeroshot pilpieline for sentiment classification from EEG. The interesting part is that it can can leverage data from various subjects and sources, i.e huge potential for EEG to text systems with enough data.</p>
<p>Interesting quote from paper:</p>
<p><em>The high-level idea is that we assume the human
brain to be a special kind of encoder, which functions similar to a language model that encodes a sequence of English tokens into contextualized embeddings</em></p>
<p>I am primarily interested in the seq2seq model they managed to build from EEG data.</p>
<p>Important components that they used:</p>
<ul>
<li>word-level EEG features. (can be considered EEG &ldquo;tokens&rdquo;?)</li>
<li>A multi layer transformer encoder to encode EEG features</li>
<li>a pre-trained encoder-decoder BART model</li>
</ul>
<p>They were able to successfully train a model for sentence reconstruction with cross entropy loss. The results are not amazing, but its proves that this direction of research is definitely worth pursuing.</p>



      
        <div class="blog-tags">
          
            <a href="https://mayukhdeb.github.io/notes//tags/paper/">paper</a>&nbsp;
          
        </div>
      
    </article>
    
  </div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2023
      </p>
  </div>
</footer></body>
</html>
