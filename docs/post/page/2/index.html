<!DOCTYPE html>
<html lang="en"><meta charset="utf-8" />

  <title>Writing - Notes</title>


<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/latex.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/main.css" />
<link rel="stylesheet" href="https://mayukhdeb.github.io/notes/css/darkmode.css" />
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="generator" content="Hugo 0.68.3" /><body>






<header>
  <nav class="navbar">
  <div class="nav">
    

    <ul class="nav-links">
      
    </ul>
  </div>
</nav>
  <div class="intro-header">
    <div class="container">
      <div class="post-heading">
        
          <h1>Writing</h1>
          
        
      </div>
    </div>
  </div>
</header>
<div id="content">
<div class="container" role="main">
    <div class="posts-list">
      
        
      

      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-14-07-lms-mostly-know-what-they-know/">
      <h2 class="post-title">Language Models (mostly) Know What they know</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Jul 14, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Can we make LMs predict which questions they&rsquo;ll be able to answer correctly? It is important for LLMs to &ldquo;know&rdquo; what they know and what they do not know. The problem is that LMs are generally never trained to say &ldquo;I do not know&rdquo;. But it might be possible to quantify this ability post-training.
This is how they approach the problem:
 Finetune models with a value head to predict the probabiility that they can answer a given question correctly.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-14-07-lms-mostly-know-what-they-know/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-attention_flow/">
      <h2 class="post-title">Attention Rollout</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 16, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>How is it better than just viewing raw attention maps ? Viewing raw attention maps as a way to explain transformers does not take into account the fact that we also have residual connections in the model. When we only use attention weights to approximate the flow of information in Transformers, we ignore the residual connections. But these connections play a significant role in tying corresponding positions in different layers.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-attention_flow/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
        <article class="post-preview">
  <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-generic_attention_model_explainability/">
      <h2 class="post-title">Generic Attention-model Explainability</h2>
  </a>
  <div class="postmeta">
    <span class="meta-post">
  <i class="fa fa-calendar-alt"></i>Apr 16, 2022
  
</span>
  </div>
  <div class="post-entry">
    
      <p>Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers Can be used to explain models like CLIP. This is how it works:
  First, let us define an input image x_image and a list of input texts [a, b, c] where a, b and c can be any strings which can be tokenized and fed into the model.
input_texts = [&#34;a bald man&#34;, &#34;a rocket in space&#34;, &#34;a man&#34;]   We do a forward pass with a tokenized image and text(s) on CLIP, and obtain logits_per_image and logits_per_text.</p>
        <a href="https://mayukhdeb.github.io/notes/post/2022-04-16-generic_attention_model_explainability/" class="post-read-more">Read More</a>
    
  </div>
</article>
      
      </div>
    
    <ul class="pager">
      
        <li class="previous">
          <a href="https://mayukhdeb.github.io/notes/post/page/1/">&larr; Newer</a>
        </li>
      
      
        <li class="next">
          <a href="https://mayukhdeb.github.io/notes/post/page/3/">Older &rarr;</a>
        </li>
      
    </ul>
  
</div>

        </div><footer>
  <div class="container">
    <p class="credits copyright">
      <p class="credits theme-by">
        Powered By <a href="https://gohugo.io">Hugo</a>&nbsp;/&nbsp;Theme&nbsp;<a href="https://github.com/HelloRusk/HugoTeX">HugoTeX</a>
        <br>
        <a href="https://mayukhdeb.github.io/notes/about">Mayukh Deb</a>
        &copy;
        2022
      </p>
  </div>
</footer></body>
</html>
