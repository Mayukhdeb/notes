<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Notes</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Notes</h1>
</header>
<p>This is where I keep my notes.</p>
<h2 id="posts">Posts</h2>
<ul>
<li><a href="posts/2024-02-10-optically-pumped-magnetometers.md.html">Optically Pumped Magnetometers</a></li>
<li><a href="posts/2024-02-10-animatediff-svd-moonshot.md.html">Video Generation Models</a></li>
<li><a href="posts/2024-01-16-dpo-diffusion.md.html">Direct Preference Optimization for Diffusion Models</a></li>
<li><a href="posts/2023-07-02-svd.md.html">Singular Value Decomposition</a></li>
<li><a href="posts/2023-07-02-matrices.md.html">Matrices</a></li>
<li><a href="posts/2023-06-27-dreamsim.md.html">DreamSim</a></li>
<li><a href="posts/2023-05-30-mindeye.md.html">MindEye: fMRI-to-Image with Contrastive Learning</a></li>
<li><a href="posts/2023-05-10-brain-inspired-model-training.md.html">BIMT: Brain Inspired Modular Training</a></li>
<li><a href="posts/2023-04-20-audioclip.md.html">AudioCLIP: Extending CLIP to Image, Text and Audio</a></li>
<li><a href="posts/2023-04-04-things-meg-dataset.md.html">THINGS: a multimodal dataset for investigating object representations in thehuman brain</a></li>
<li><a href="posts/2023-01-25-open-vocab-eeg-text-decoding.md.html">Open Vocabulary EEG-To-Text Decoding</a></li>
<li><a href="posts/2023-01-25-brain2image-gan.md.html">Brain2Image: Converting Brain Signals into Images</a></li>
<li><a href="posts/2023-01-01-neural-taskonomy.md.html">Neural Taskonomy - using encodings from vision models to understand the human brain</a></li>
<li><a href="posts/2022-19-07-locating-and-editing-factual-associations-in-gpt.md.html">Locating and Editing Factual Knowledge in GPTs</a></li>
<li><a href="posts/2022-14-07-lms-mostly-know-what-they-know.md.html">Language Models (mostly) Know What they know</a></li>
<li><a href="posts/2022-12-25-diffusion.md.html">Order From Chaos (Part 1): Diffusion for image synthesis explained in simple words</a></li>
<li><a href="posts/2022-12-25-diffusion-code.md.html">Order From Chaos (Part 2): Diffusion for image synthesis explained in code and a little bit of math</a></li>
<li><a href="posts/2022-12-24-clip-fields.md.html">CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory</a></li>
<li><a href="posts/2022-12-18-clippo-image-and-language-understanding-from-text-only.md.html">CLIPPO: Image and Language understanding from pixels only</a></li>
<li><a href="posts/2022-11-20-clip-fields.md.html">VPT: Video Pre-Training on Minecraft</a></li>
<li><a href="posts/2022-11-19-brain-to-text-communication-via-handwriting.md.html">Brain to Text Communication via handwriting</a></li>
<li><a href="posts/2022-10-31-craftassist.md.html">CraftAssist - LLMs on minecraft (?)</a></li>
<li><a href="posts/2022-09-27-ai-through-lens-of-cogsci.md.html">Watching artificial intelligence through the lens of CogSci</a></li>
<li><a href="posts/2022-09-03-new-science-of-common-sense.md.html">Towards a New Science of Common Sense</a></li>
<li><a href="posts/2022-08-07-parti-image-generation.md.html">Parti - Scaling LLMs for Text to Image tasks</a></li>
<li><a href="posts/2022-08-01-the-third-wave.md.html">The Third Wave (?)</a></li>
<li><a href="posts/2022-04-16-transformer_interpretability_beyond_attention.md.html">Transformer intrepretability beyond attention</a></li>
<li><a href="posts/2022-04-16-self-consistency-imrpoves-chain-of-thought.md.html">Self-Consistency Improves Chain of Thought Reasoning in LMs</a></li>
<li><a href="posts/2022-04-16-lost-unsupervised-object-detection.md.html">LOST - Localizing objects with self supervised transformers</a></li>
<li><a href="posts/2022-04-16-knowledge_neurons.md.html">Knowledge Neurons</a></li>
<li><a href="posts/2022-04-16-interpreting-language-models-with-contrastive-explanations.md.html">Interpreting LMs with contrastive explanations</a></li>
<li><a href="posts/2022-04-16-generic_attention_model_explainability.md.html">Generic Attention-model Explainability</a></li>
<li><a href="posts/2022-04-16-attention_flow.md.html">Attention Rollout</a></li>
</ul>
</body>
</html>
